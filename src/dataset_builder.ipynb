{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bea961a",
   "metadata": {},
   "source": [
    "# Dataset Builder for FER2013+ utility Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26213a5b",
   "metadata": {},
   "source": [
    "**Description**: This module processes the FER2013+ dataset, detecting faces and landmarks, and saving the processed data into .npz files for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9ba680",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3119a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from preprocessing.face_detection import FaceDetectorMP\n",
    "from preprocessing.landmark_detection import LandmarkDetectorMP\n",
    "from utils.logger import get_logger\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b67cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger setup\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196587f",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07c6f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_per_class(dataset_dir):\n",
    "    \"\"\"\n",
    "    Count the number of images per class in a dataset directory.\n",
    "    Args:\n",
    "        dataset_dir (str or Path): Path to the 'train' or 'test' dataset folder.\n",
    "    Returns:\n",
    "        dict: Dictionary mapping class names to number of images.\n",
    "    \"\"\"\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    class_counts = {}\n",
    "\n",
    "    for class_dir in sorted(dataset_dir.iterdir()):\n",
    "        if class_dir.is_dir():\n",
    "            image_count = len(list(class_dir.glob(\"*\")))\n",
    "            class_counts[class_dir.name] = image_count\n",
    "\n",
    "    # Mostrar los resultados ordenados de menor a mayor\n",
    "    print(\"Conteo de imágenes por clase:\")\n",
    "    for class_name, count in sorted(class_counts.items(), key=lambda x: x[1]):\n",
    "        print(f\"  - {class_name}: {count} imágenes\")\n",
    "    \n",
    "    return class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dfaf978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de imágenes por clase:\n",
      "  - contempt: 165 imágenes\n",
      "  - disgust: 191 imágenes\n",
      "  - fear: 652 imágenes\n",
      "  - anger: 2466 imágenes\n",
      "  - sadness: 3514 imágenes\n",
      "  - surprise: 3562 imágenes\n",
      "  - happiness: 7528 imágenes\n",
      "  - neutral: 10308 imágenes\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"../data/fer2013plus/train\"\n",
    "train_class_count = count_images_per_class(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243cae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de imágenes por clase:\n",
      "  - contempt: 51 imágenes\n",
      "  - disgust: 57 imágenes\n",
      "  - fear: 167 imágenes\n",
      "  - anger: 644 imágenes\n",
      "  - sadness: 856 imágenes\n",
      "  - surprise: 900 imágenes\n",
      "  - happiness: 1827 imágenes\n",
      "  - neutral: 2597 imágenes\n"
     ]
    }
   ],
   "source": [
    "test_dir = \"../data/fer2013plus/test\"\n",
    "test_class_count = count_images_per_class(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97319015",
   "metadata": {},
   "source": [
    "Desbalance de clases muy desproporcionado, se opta por descartar clases con baja representación, pues no se tiene certeza de cuantas imágenes si lograran ser detectadas.\n",
    "Clases a eliminar `contempt`, `disgust` y `fear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba8f4c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_partition(partition_dir, detector, landmarker, balance_train=False):\n",
    "    \"\"\"\n",
    "    Process a single partition of the dataset (train or test).\n",
    "    Args:\n",
    "        partition_dir (str): Path to the partition directory (train or test).\n",
    "        detector (FaceDetectorMP): Face detection instance.\n",
    "        landmarker (LandmarkDetectorMP): Landmark detection instance.\n",
    "        balance_train (bool): Whether to apply class balancing (only for train).\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: Processed features and labels as numpy arrays.\n",
    "    \"\"\"\n",
    "    # Define the allowed classes for FER2013+ (removed underrepresented classes)\n",
    "    # Removed: \"contempt\", \"disgust\", \"fear\"\n",
    "    allowed_classes = {\"anger\", \"sadness\", \"surprise\", \"happiness\", \"neutral\"}\n",
    "    # Ensure the partition directory exists\n",
    "    partition_name = Path(partition_dir).name\n",
    "    logger.info(f\"Processing partition: {Path(partition_dir).as_posix()}\")\n",
    "\n",
    "    # Initialize data structures\n",
    "    class_vectors = {}  # class_name -> list of vectors\n",
    "    class_labels = {}   # class_name -> list of label indices\n",
    "    label_map = {}      # class_name -> integer label\n",
    "    skipped_total = defaultdict(int)\n",
    "\n",
    "    # Check if the partition directory exists\n",
    "    label_dirs = sorted(os.listdir(partition_dir))\n",
    "    label_index_counter = 0\n",
    "\n",
    "    # Iterate over each class directory\n",
    "    for label_name in label_dirs:\n",
    "        # Skip if the label is not in the allowed classes\n",
    "        if label_name not in allowed_classes:\n",
    "            logger.info(f\"Skipping class '{label_name}' (not in allowed list)\")\n",
    "            continue\n",
    "\n",
    "        # Skip if the label directory does not exist\n",
    "        label_path = os.path.join(partition_dir, label_name)\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "        \n",
    "        # Count images in the class directory and sort them\n",
    "        images = sorted(os.listdir(label_path))\n",
    "        logger.info(f\"Processing class '{label_name}' with {len(images)} images\")\n",
    "        vectors, labels = [], []\n",
    "        # Initialize skipped counts for this class\n",
    "        skipped_counts = defaultdict(int)\n",
    "\n",
    "        # Process each image in the class directory\n",
    "        for image_name in tqdm(images, desc=label_name, leave=False):\n",
    "            # Get the full path of the image\n",
    "            image_path = os.path.join(label_path, image_name)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Check if the image was read successfully\n",
    "            if image is None:\n",
    "                skipped_counts[\"failed_read\"] += 1\n",
    "                continue\n",
    "            \n",
    "            # Detect face on the image\n",
    "            detection_result = detector.detect_faces(image)\n",
    "            if detection_result is None:\n",
    "                skipped_counts[\"no_face_detected\"] += 1\n",
    "                continue\n",
    "            \n",
    "            # Crop the face from the image\n",
    "            cropped = detector.crop_face(image, detection_result)\n",
    "            if cropped is None:\n",
    "                skipped_counts[\"failed_crop\"] += 1\n",
    "                continue\n",
    "            \n",
    "            # Detect landmarks on the cropped face\n",
    "            landmark_result = landmarker.detect_landmarks(cropped)\n",
    "            if landmark_result is None:\n",
    "                skipped_counts[\"no_landmarks_detected\"] += 1\n",
    "                continue\n",
    "\n",
    "            # Extract the landmark vector\n",
    "            vector = landmarker.extract_landmark_vector(landmark_result)\n",
    "            if vector is None:\n",
    "                skipped_counts[\"vector_extraction_failed\"] += 1\n",
    "                continue\n",
    "            \n",
    "            # Add the vector and label to the lists\n",
    "            vectors.append(vector)\n",
    "            labels.append(label_index_counter)\n",
    "\n",
    "        # Log the results for this class\n",
    "        logger.info(f\"Processed {len(vectors)} valid images for class '{label_name}'\")\n",
    "        for k, v in skipped_counts.items():\n",
    "            logger.info(f\"  Skipped {k}: {v}\")\n",
    "            skipped_total[k] += v\n",
    "\n",
    "        # Check if we have valid vectors for this class\n",
    "        if len(vectors) > 0:\n",
    "            class_vectors[label_name] = vectors\n",
    "            class_labels[label_name] = labels\n",
    "            label_map[label_name] = label_index_counter\n",
    "            label_index_counter += 1\n",
    "\n",
    "    # Dynamically adjust the class count based on processed classes\n",
    "    if balance_train:\n",
    "        # Balance classes by selecting the minimum number of samples across all classes\n",
    "        min_samples = min(len(v) for v in class_vectors.values())\n",
    "        logger.info(f\"Balancing classes to {min_samples} samples each\")\n",
    "\n",
    "        # Create a balanced dataset by selecting min_samples from each class\n",
    "        all_features = []\n",
    "        all_labels = []\n",
    "        # Iterate over each class and select min_samples\n",
    "        for class_name in class_vectors:\n",
    "            # Select min_samples from each class\n",
    "            selected_vectors = class_vectors[class_name][:min_samples]\n",
    "            selected_labels = class_labels[class_name][:min_samples]\n",
    "            all_features.extend(selected_vectors)\n",
    "            all_labels.extend(selected_labels)\n",
    "    else:\n",
    "        # No balancing, concatenate all vectors and labels (for test split)\n",
    "        all_features = [v for vectors in class_vectors.values() for v in vectors]\n",
    "        all_labels = [l for labels in class_labels.values() for l in labels]\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    features_array = np.array(all_features, dtype=np.float32)\n",
    "    labels_array = np.array(all_labels, dtype=np.int32)\n",
    "\n",
    "    logger.info(f\"Final sample count for {partition_name}: {len(features_array)}\")\n",
    "    logger.info(\"Global skipped summary:\")\n",
    "    for k, v in skipped_total.items():\n",
    "        logger.info(f\"  {k}: {v}\")\n",
    "\n",
    "    # Return the processed features and labels as numpy arrays\n",
    "    return features_array, labels_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41731ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(data_dir=\"../data/fer2013plus\", output_dir=\"../data/processed\"):\n",
    "    \"\"\"\n",
    "    Build the FER2013+ dataset by processing images from the specified data directory.\n",
    "    Applies balancing only to the training partition.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the root directory containing 'train' and 'test' partitions.\n",
    "        output_dir (str): Path to the directory where processed dataset will be saved.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize face detector and landmark detector\n",
    "    detector = FaceDetectorMP()\n",
    "    landmarker = LandmarkDetectorMP()\n",
    "\n",
    "    # Process each partition (train and test)\n",
    "    for partition in [\"train\", \"test\"]:\n",
    "        # Ensure the partition directory exists\n",
    "        partition_dir = os.path.join(data_dir, partition)\n",
    "        # Mark if we are balancing the training set\n",
    "        balance_train = (partition == \"train\")\n",
    "        # Process the partition directory\n",
    "        features, labels = process_partition(partition_dir, detector, landmarker, balance_train)\n",
    "        # Save the processed features and labels to a compressed .npz file\n",
    "        output_path = os.path.join(output_dir, f\"{partition}.npz\")\n",
    "        np.savez_compressed(output_path, features=features, labels=labels)\n",
    "        logger.info(f\"Saved {Path(partition_dir).as_posix()} dataset with {len(features)} samples to: {Path(output_path).as_posix()}\")\n",
    "\n",
    "    logger.info(\"Dataset building completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e5ab9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Processing partition: ../data/fer2013plus/train\n",
      "[INFO] Processing class 'anger' with 2466 images\n",
      "[INFO] Processed 1598 valid images for class 'anger'      \n",
      "[INFO]   Skipped no_landmarks_detected: 568\n",
      "[INFO]   Skipped no_face_detected: 300\n",
      "[INFO] Skipping class 'contempt' (not in allowed list)\n",
      "[INFO] Skipping class 'disgust' (not in allowed list)\n",
      "[INFO] Skipping class 'fear' (not in allowed list)\n",
      "[INFO] Processing class 'happiness' with 7528 images\n",
      "[INFO] Processed 6606 valid images for class 'happiness'      \n",
      "[INFO]   Skipped no_landmarks_detected: 704\n",
      "[INFO]   Skipped no_face_detected: 218\n",
      "[INFO] Processing class 'neutral' with 10308 images\n",
      "[INFO] Processed 8428 valid images for class 'neutral'        \n",
      "[INFO]   Skipped no_landmarks_detected: 1463\n",
      "[INFO]   Skipped no_face_detected: 417\n",
      "[INFO] Processing class 'sadness' with 3514 images\n",
      "[INFO] Processed 2343 valid images for class 'sadness'      \n",
      "[INFO]   Skipped no_face_detected: 366\n",
      "[INFO]   Skipped no_landmarks_detected: 805\n",
      "[INFO] Processing class 'surprise' with 3562 images\n",
      "[INFO] Processed 2960 valid images for class 'surprise'      \n",
      "[INFO]   Skipped no_landmarks_detected: 477\n",
      "[INFO]   Skipped no_face_detected: 125\n",
      "[INFO] Balancing classes to 1598 samples each\n",
      "[INFO] Final sample count for train: 7990\n",
      "[INFO] Global skipped summary:\n",
      "[INFO]   no_landmarks_detected: 4017\n",
      "[INFO]   no_face_detected: 1426\n",
      "[INFO] Saved ../data/fer2013plus/train dataset with 7990 samples to: ../data/processed/train.npz\n",
      "[INFO] Processing partition: ../data/fer2013plus/test\n",
      "[INFO] Processing class 'anger' with 644 images\n",
      "[INFO] Processed 428 valid images for class 'anger'     \n",
      "[INFO]   Skipped no_landmarks_detected: 142\n",
      "[INFO]   Skipped no_face_detected: 74\n",
      "[INFO] Skipping class 'contempt' (not in allowed list)\n",
      "[INFO] Skipping class 'disgust' (not in allowed list)\n",
      "[INFO] Skipping class 'fear' (not in allowed list)\n",
      "[INFO] Processing class 'happiness' with 1827 images\n",
      "[INFO] Processed 1601 valid images for class 'happiness'      \n",
      "[INFO]   Skipped no_face_detected: 40\n",
      "[INFO]   Skipped no_landmarks_detected: 186\n",
      "[INFO] Processing class 'neutral' with 2597 images\n",
      "[INFO] Processed 2099 valid images for class 'neutral'      \n",
      "[INFO]   Skipped no_landmarks_detected: 378\n",
      "[INFO]   Skipped no_face_detected: 120\n",
      "[INFO] Processing class 'sadness' with 856 images\n",
      "[INFO] Processed 592 valid images for class 'sadness'     \n",
      "[INFO]   Skipped no_landmarks_detected: 192\n",
      "[INFO]   Skipped no_face_detected: 72\n",
      "[INFO] Processing class 'surprise' with 900 images\n",
      "[INFO] Processed 722 valid images for class 'surprise'     \n",
      "[INFO]   Skipped no_face_detected: 40\n",
      "[INFO]   Skipped no_landmarks_detected: 138\n",
      "[INFO] Final sample count for test: 5442\n",
      "[INFO] Global skipped summary:\n",
      "[INFO]   no_landmarks_detected: 1036\n",
      "[INFO]   no_face_detected: 346\n",
      "[INFO] Saved ../data/fer2013plus/test dataset with 5442 samples to: ../data/processed/test.npz\n",
      "[INFO] Dataset building completed.\n"
     ]
    }
   ],
   "source": [
    "# Call the function to build the dataset\n",
    "build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d699604",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Label map saved to ../data/processed/label_map.json\n"
     ]
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: \"anger\",\n",
    "    1: \"happiness\",\n",
    "    2: \"neutral\",\n",
    "    3: \"sadness\",\n",
    "    4: \"surprise\"\n",
    "}\n",
    "\n",
    "import json\n",
    "with open(\"../data/processed/label_map.json\", \"w\") as f:\n",
    "    json.dump(label_map, f, indent=2)\n",
    "logger.info(\"Label map saved to ../data/processed/label_map.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb06957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7990, 1434)\n",
      "(7990,)\n",
      "[1598 1598 1598 1598 1598]\n"
     ]
    }
   ],
   "source": [
    "data = np.load(\"../data/processed/train.npz\")\n",
    "print(data[\"features\"].shape)  # (7990, N)\n",
    "print(data[\"labels\"].shape)    # (7990,)\n",
    "print(np.bincount(data[\"labels\"]))  # Verify class distribution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
